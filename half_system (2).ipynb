{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "ROOT = 'C:\\\\Users\\\\Indrani Rana\\\\OneDrive\\\\Desktop\\\\project\\\\dada_half_systems'\n",
    "DATA = 'C:\\\\Users\\\\Indrani Rana\\\\OneDrive\\\\Desktop\\\\project\\\\dada_half_systems\\\\SOSData'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- IMPORT Dataset and Normalize ------------------------------------------------------+\n",
    "def load_data(data_loc,n_exp):\n",
    "    '''\n",
    "        data_loc: location of the data\n",
    "        n_exp: no of data\n",
    "    '''\n",
    "    SOS_data = []            # N-D array data\n",
    "    dfs = dict()             # each experiment as dataframe\n",
    "    exps = []                # name of experiments, ['Exp1.txt,Exp2.txt,...]\n",
    "    for i in range(1,n_exp+1):\n",
    "        exps.append('Exp'+str(i)+'.txt')\n",
    "\n",
    "    for exp in sorted(exps):\n",
    "        df = pd.read_csv(data_loc+'/'+exp,delimiter='\\t') # read txt file\n",
    "        df = df.set_index(df.columns[0])\n",
    "        #print(list(df.index))\n",
    "        global gene_names\n",
    "        gene_names = list(df.index)\n",
    "        dfs[exp]=df\n",
    "\n",
    "        # convert to numpy array of [8 X 50] \n",
    "        # [8 --> operons, 50 --> time points(0,6,12,18,..)]\n",
    "\n",
    "        df_numpy = df.to_numpy()\n",
    "        SOS_data.append(df_numpy)\n",
    "\n",
    "    SOS_data = np.stack(SOS_data,axis=0)\n",
    "\n",
    "    \n",
    "    return SOS_data #,dfs if dataframes are required for individual experiment\n",
    "\n",
    "\n",
    "\n",
    "def data_normalize(data):\n",
    "    '''\n",
    "        data : shape of [4x8x50]\n",
    "    '''\n",
    "    data1 = []\n",
    "    for i in range(0,data.shape[0]):\n",
    "        normalizedData = (data[i]-np.min(data[i]))/(np.max(data[i])-np.min(data[i]))\n",
    "        data1.append(normalizedData)\n",
    "    data1 = np.stack(data1,axis=0)\n",
    "    return data1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(x_j_t,f_ij):\n",
    "    '''\n",
    "        x_j_t :     actual value of j-th gene at t-th time point [1 x N]\n",
    "        f_ij :      extracted f_ij from P_g [1 x N]\n",
    "\n",
    "    '''\n",
    "    temp = []\n",
    "    for j in range(0,len(x_j_t)):\n",
    "        temp.append(pow(x_j_t[j],f_ij[j]))\n",
    "    return np.sum(temp)\n",
    "\n",
    "def obj(X_i, X_pred_i):\n",
    "    '''\n",
    "        X_i :       actual data points of i-th gene [1 x 50]\n",
    "        X_pred_i :  predicted data points of i-th gene [1 x 50]\n",
    "\n",
    "    '''\n",
    "    T = len(X_i)\n",
    "    sum = 0\n",
    "    for t in range(0,T):\n",
    "        sum = sum + (X_i[t] - X_pred_i[t])\n",
    "    return sum/T\n",
    "\n",
    "\n",
    "def fitness_particles(X,g,P_g):\n",
    "    '''\n",
    "        X :         actual data of genes with 50 time points [N x 50]\n",
    "        g :         current gene \n",
    "        P_g :       particle postions of current gene\n",
    "    '''\n",
    "\n",
    "    # Extract number of genes \n",
    "    N = X.shape[0]\n",
    "    # Extract number of time points\n",
    "    tp = X.shape[1]\n",
    "    # Extract population size\n",
    "    ps = P_g.shape[1]\n",
    "    #print(ps)\n",
    "\n",
    "    # error of all particles\n",
    "    err_g = np.zeros((ps))\n",
    "\n",
    "    for i in range(0,ps):\n",
    "        # Extract f_ij_g, which is a array of N elements [f_i1, f_i2, ...... f_iN] for each i-th particle\n",
    "        # also extract del_i, sci_i, and meu_i out of P_g or i-th particle p_i_g\n",
    "\n",
    "        f_ij = P_g[g,i,:N]      # [1 x N]\n",
    "        del_i = P_g[g,i,N]      # [1]\n",
    "        sci_i = P_g[g,i,N+1]    # [1]\n",
    "        meu_i = P_g[g,i,N+2]    # [1]\n",
    "\n",
    "        for t in range(2,tp):\n",
    "            # diff. between the (t-1)-th predicted data point and actual data point of g-th gene\n",
    "            d_i = X[g,t-1] - X_pred[g,t-1]\n",
    "\n",
    "            # Calculate the predicted expression level x_pred_i(t) of g-th gene from x_i(t-1)\n",
    "            X_pred[g,t] = dt * (del_i * pi(X[:,t-1],f_ij)) + (1 - dt * sci_i) * X[g,t-1] + meu_i * d_i\n",
    "        \n",
    "        # error of i-th particle of g-th gene\n",
    "\n",
    "        err_i_g = obj(X[g],X_pred[g])\n",
    "\n",
    "        err_g[i] = err_i_g\n",
    "    \n",
    "    return err_g\n",
    "\n",
    "\n",
    "def update_solution(p_g,per_best,per_best_err,gl_best,min_idx,err,best_fit):\n",
    "    ps = p_g.shape[0]\n",
    "\n",
    "    for i in range(0,ps):\n",
    "        #print(err)\n",
    "        if err[i] < per_best_err[i]:\n",
    "            per_best_err[i] = err[i]\n",
    "            per_best[i] = p_g[i]\n",
    "        if err[i] < best_fit:\n",
    "            best_fit = err[i]\n",
    "            gl_best = p_g[i]\n",
    "            min_idx = i\n",
    "    return per_best,per_best_err,gl_best,best_fit,min_idx\n",
    "\n",
    "def gen_random_numbers_in_range(low, high, n):\n",
    "    return random.sample(range(low, high), n)\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def BAPSO(N,maxit,ps,X):\n",
    "    '''\n",
    "        N :         Number of Genes\n",
    "        maxit :     total number of iterations\n",
    "        ps :        population size\n",
    "        X :         data of shape [8x50]      \n",
    "    '''\n",
    "    # initialize position vector(P_g)  = random and velocity vector(V_g) = zeros for all N genes\n",
    "    # each p_i_g of P_g (for each gene) is defined as [f_i_1, f_i_2, ...... f_i_N, del_i, sci_i, meu_i], which is a size of (1 x N+3)\n",
    "    # then, total size of P_g is (N x ps x N+3)\n",
    "\n",
    "    P_g = np.random.rand(N,ps,N+3)\n",
    "    V_g = np.zeros((N,ps,N+3))\n",
    "\n",
    "\n",
    "    # making f_ij sparse\n",
    "    for g in range(0,N):\n",
    "        for pos in range(0,ps):\n",
    "            P_g[g,pos,:N] = 0\n",
    "            idx = gen_random_numbers_in_range(0,N,4)\n",
    "            P_g[g,pos,idx[0]] = P_g[g,pos,idx[1]] = P_g[g,pos,idx[2]] = P_g[g,pos,idx[3]] =1 \n",
    "    #print(P_g)\n",
    "\n",
    "\n",
    "\n",
    "    # pred data point matrix [N x 50]\n",
    "    global X_pred\n",
    "    X_pred = np.zeros((X.shape),dtype=np.float32)\n",
    "\n",
    "    # the del_t, which is 6 mins\n",
    "    global dt \n",
    "    dt = 6 * 60 # in sec\n",
    "\n",
    "    # error matrix of all particles of all genes\n",
    "    global err\n",
    "    err = np.zeros((N,ps))\n",
    "\n",
    "\n",
    "    # all best solutions\n",
    "    GB = []\n",
    "\n",
    "    for g in range(0,N):\n",
    "        err_g = fitness_particles(X,g,P_g)\n",
    "\n",
    "        min_idx = np.argmin(err_g) # find the particle index with minimum value\n",
    "        best_fit = err_g[min_idx]   # fitness of that index\n",
    "\n",
    "        # initialize personal best solutions PB_g [1 x ps] and its fitness PE_g [1 x ps]\n",
    "        PB_g = P_g[g] # position [ps x (N+3)]\n",
    "        PE_g = err_g  # error    [1 x ps]\n",
    "\n",
    "        # calculate the global best soluton gb_g = PB_g[min_idx]\n",
    "        gb_g = PB_g[min_idx] # [1 x (N+3)]\n",
    "\n",
    "        err[g] = err_g\n",
    "\n",
    "        for it in tqdm.tqdm(range(1,maxit),desc=\"Gene {}\".format(g+1)):\n",
    "\n",
    "            inertia_comp = r0 * V_g[g]      # [ps x (N+3)]\n",
    "            cognitive_comp = c1 * r[0] * (PB_g - P_g[g])     # the particleâ€™s memory, causing it to tend to return to \n",
    "                                                                    # the regions of the search space in which it has experienced high individual fitness\n",
    "\n",
    "            social_comp = c2 * r[1] * (gb_g - P_g[g])         # causes the particle to move to the best region the swarm has found so far\n",
    "\n",
    "            next_v =  inertia_comp + cognitive_comp + social_comp\n",
    "\n",
    "            next_p = P_g[g] + next_v\n",
    "            #print(next_v.shape,V_g.shape,gb_g.shape)\n",
    "\n",
    "            # updating the velocity and position\n",
    "            V_g[g] = next_v\n",
    "\n",
    "            P_g[g] = next_p\n",
    "\n",
    "\n",
    "            err_g = fitness_particles(X,g,P_g)\n",
    "\n",
    "            PB_g, PE_g, gb_g, best_fit, min_idx = update_solution(P_g[g],PB_g,PE_g,gb_g,min_idx,err_g,best_fit)\n",
    "        \n",
    "\n",
    "        GB.append(gb_g)\n",
    "    GB = np.stack(GB,0)\n",
    "\n",
    "    return GB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data - 0\n",
      "Iteration-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gene 1:   0%|          | 0/2999 [00:00<?, ?it/s]C:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  temp.append(pow(x_j_t[j],f_ij[j]))\n",
      "C:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py:57: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  X_pred[g,t] = dt * (del_i * pi(X[:,t-1],f_ij)) + (1 - dt * sci_i) * X[g,t-1] + meu_i * d_i\n",
      "C:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sum = sum + (X_i[t] - X_pred_i[t])\n",
      "Gene 1:   9%|â–‰         | 283/2999 [00:15<02:29, 18.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/2466384418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iteration-{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mGB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBAPSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mf_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py\u001b[0m in \u001b[0;36mBAPSO\u001b[1;34m(N, maxit, ps, X)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0merr_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness_particles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mPB_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPE_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_g\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPB_g\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPE_g\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgb_g\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merr_g\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py\u001b[0m in \u001b[0;36mfitness_particles\u001b[1;34m(X, g, P_g)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# Calculate the predicted expression level x_pred_i(t) of g-th gene from x_i(t-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mX_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdel_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_ij\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msci_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmeu_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# error of i-th particle of g-th gene\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1595326886.py\u001b[0m in \u001b[0;36mpi\u001b[1;34m(x_j_t, f_ij)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_j_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_j_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_ij\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pred_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2245\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2247\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "np.random.seed(10)\n",
    "\n",
    "global c1,c2,r0,r\n",
    "r0 = np.random.uniform(0,1) # constant inertia weight (how much to weigh the previous velocity) in PSO and random in BAPSO\n",
    "c1=2                        # cognative constant\n",
    "c2=2                        # social constant\n",
    "r = np.random.rand(2)       # r1,r2\n",
    "maxit = 3000\n",
    "ps = 70\n",
    "\n",
    "for_all_data = []\n",
    "\n",
    "\n",
    "n_exp = 4                           # total dataset\n",
    "data = load_data(DATA,n_exp)        # load data 4 X 8 X 50\n",
    "norm_data = data_normalize(data)    # normalize data\n",
    "\n",
    "for d in range(0,norm_data.shape[0]):\n",
    "    print(\"Data - {}\".format(d))\n",
    "\n",
    "    data0 = data[d]                     # (1st) one of 4 datasets [8 x 50]\n",
    "    norm_data0 = norm_data[d]           # norm of that 1st\n",
    "\n",
    "\n",
    "    N = norm_data0.shape[0]\n",
    "    L = 10                              # No  of experiment for each generated GRN\n",
    "\n",
    "    PS_ij = np.zeros((N,N))\n",
    "    for l in range(0,L):\n",
    "\n",
    "        print(\"Iteration-{}\".format(l+1))\n",
    "        GB = BAPSO(8,maxit,ps,data0) # Gb = 1x11\n",
    "\n",
    "        f_ij = GB[:,:N] # NxN\n",
    "        PS_ij = PS_ij + f_ij\n",
    "\n",
    "    PS_ij = PS_ij/L\n",
    "\n",
    "\n",
    "    # threshold\n",
    "    ths = 0.9 #phi\n",
    "    #print(PS_ij)\n",
    "    PS_ij[PS_ij>ths] = 1\n",
    "    PS_ij[PS_ij==ths] = 1\n",
    "    PS_ij[PS_ij<ths] = 0\n",
    "\n",
    "    g_ij = PS_ij\n",
    "\n",
    "    for_all_data.append(g_ij)\n",
    "\n",
    "\n",
    "#print(GB[:,:N])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_loc = 'C:\\\\Users\\\\Indrani Rana\\\\OneDrive\\\\Desktop\\\\project\\\\dada_half_systems\\\\result2_3000'\n",
    "def save_matrices(matrix,saved_loc):\n",
    "    '''\n",
    "        matrix : an N number of 2-D matrices\n",
    "\n",
    "    '''\n",
    "\n",
    "    N = len(matrix)\n",
    "    for i in range(0,N):\n",
    "        name = 'data_{}'.format(i+1)+'.txt'\n",
    "        print(i,name)\n",
    "        loc = saved_loc + '/' + name\n",
    "\n",
    "        np.savetxt(loc,matrix[i])\n",
    "\n",
    "        print(\"File saved at {}\".format(saved_loc))\n",
    "\n",
    "# saved data level\n",
    "\n",
    "save_matrices(for_all_data,saved_loc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data)\n",
    "\n",
    "def find_edges(f_ij):\n",
    "    edges = []\n",
    "    for g1 in range(0,f_ij.shape[0]):\n",
    "        for g2 in range(0,f_ij.shape[1]):\n",
    "\n",
    "            if f_ij[g1,g1] == 1:\n",
    "                edges.append((gene_names[g1],gene_names[g2]))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def plot(edges):\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    G = nx.MultiDiGraph\n",
    "    G.add_edges_from(edges)\n",
    "    #values = [val_map.get(node, 0.25) for node in G.nodes()]\n",
    "\n",
    "    black_edges = [edge for edge in G.edges()]\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G, pos, cmap=plt.get_cmap('jet'), node_size = 500)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False)\n",
    "    plt.show()\n",
    "\n",
    "edges = find_edges(for_all_data[3])\n",
    "plot(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received invalid argument(s): with_label",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\INDRAN~1\\AppData\\Local\\Temp/ipykernel_58604/1770807505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_networkx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py\u001b[0m in \u001b[0;36mdraw_networkx\u001b[1;34m(G, pos, arrows, with_labels, **kwds)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_kwds\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0minvalid_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\", \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_kwds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Received invalid argument(s): {invalid_args}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0mnode_kwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_node_kwds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Received invalid argument(s): with_label"
     ]
    }
   ],
   "source": [
    "\n",
    "import networkx as nx \n",
    "  \n",
    "edges = [(1, 2), (1, 6), (2, 3), (2, 4), (2, 6),  \n",
    "         (3, 4), (3, 5), (4, 8), (4, 9), (6, 7)] \n",
    "\n",
    "G = nx.MultiDiGraph() \n",
    "  \n",
    "G.add_edges_from(edges) \n",
    "nx.draw_networkx(G, with_label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['uvrD', 'lexA', 'umuDC', 'recA', 'uvrA', 'uvrY', 'ruvA', 'polB']\n",
    "actual_edges = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uvrD', 'lexA', 'umuDC', 'recA', 'uvrA', 'uvrY', 'ruvA', 'polB']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
